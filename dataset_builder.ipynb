{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "\n",
    "def extract_sub_images(image_path):\n",
    "    \"\"\"\n",
    "    Extract sub-images from a sorted image where organisms are placed on a white background.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the sorted image\n",
    "        \n",
    "    Returns:\n",
    "        List of lists of sub-images (numpy arrays)\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    img = Image.open(image_path)\n",
    "   \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(img)\n",
    "   \n",
    "    # Find rows where all pixels are white\n",
    "    white_rows = np.all(img_array == 255, axis=(1, 2))\n",
    "   \n",
    "    # Get indices of separator rows\n",
    "    row_separators = np.where(white_rows)[0]\n",
    "   \n",
    "    # List to store all sub-images\n",
    "    all_sub_images = []\n",
    "   \n",
    "    # Process each row section\n",
    "    for i in range(len(row_separators) - 1):\n",
    "        start_row = row_separators[i] + 1\n",
    "        end_row = row_separators[i + 1]\n",
    "       \n",
    "        # Extract the row section\n",
    "        row_section = img_array[start_row:end_row]\n",
    "       \n",
    "        if row_section.shape[0] > 0:\n",
    "            # Find white columns in this section\n",
    "            white_cols = np.all(row_section >= 250, axis=(0, 2))\n",
    "           \n",
    "            # Get indices of separator columns\n",
    "            col_separators = np.where(white_cols)[0]\n",
    "           \n",
    "            # If no column separators found, add the entire row section\n",
    "            if len(col_separators) == 0:\n",
    "                sub_images_row = [row_section]\n",
    "                all_sub_images.append(sub_images_row)\n",
    "            else:\n",
    "                # Extract sub-images between column separators\n",
    "                row_sub_images = []\n",
    "               \n",
    "                # Add section before first separator\n",
    "                if col_separators[0] > 0:\n",
    "                    sub_img = row_section[:, 0:col_separators[0]]\n",
    "                    if sub_img.size > 0:\n",
    "                        row_sub_images.append(sub_img)\n",
    "               \n",
    "                # Add sections between separators\n",
    "                for j in range(len(col_separators) - 1):\n",
    "                    start_col = col_separators[j] + 1\n",
    "                    end_col = col_separators[j + 1]\n",
    "                    sub_img = row_section[:, start_col:end_col]\n",
    "                    if sub_img.size > 0:\n",
    "                        row_sub_images.append(sub_img)\n",
    "               \n",
    "                # Add section after last separator\n",
    "                if col_separators[-1] < row_section.shape[1] - 1:\n",
    "                    sub_img = row_section[:, col_separators[-1] + 1:]\n",
    "                    if sub_img.size > 0:\n",
    "                        row_sub_images.append(sub_img)\n",
    "               \n",
    "                all_sub_images.append(row_sub_images)\n",
    "   \n",
    "    return all_sub_images\n",
    "\n",
    "def squeeze_white_pixels(sub_image):\n",
    "    \"\"\"\n",
    "    Remove white rows and columns around an organism to crop it tightly.\n",
    "    \n",
    "    Args:\n",
    "        sub_image: Numpy array of the sub-image\n",
    "        \n",
    "    Returns:\n",
    "        Cropped numpy array\n",
    "    \"\"\"\n",
    "    # Find non-white rows and columns\n",
    "    non_white_rows = ~np.all(sub_image == 255, axis=(1, 2))\n",
    "    non_white_cols = ~np.all(sub_image == 255, axis=(0, 2))\n",
    "    \n",
    "    # If no non-white pixels are found, return the original image\n",
    "    if not np.any(non_white_rows) or not np.any(non_white_cols):\n",
    "        return sub_image\n",
    "    \n",
    "    # Extract only non-white rows and columns\n",
    "    return sub_image[non_white_rows][:, non_white_cols]\n",
    "\n",
    "def extract_organisms(sorted_image_path, min_size):\n",
    "    \"\"\"\n",
    "    Extract organisms from a sorted image and keep them in memory.\n",
    "    \n",
    "    Args:\n",
    "        sorted_image_path: Path to the sorted image\n",
    "        min_size: Minimum size (width/height) for an organism to be included\n",
    "        \n",
    "    Returns:\n",
    "        List of (identifier, image_array) tuples of extracted organisms\n",
    "    \"\"\"\n",
    "    # Get base name of input file without extension\n",
    "    base_name = os.path.splitext(os.path.basename(sorted_image_path))[0]\n",
    "   \n",
    "    # Extract all sub-images\n",
    "    sub_images = extract_sub_images(sorted_image_path)\n",
    "   \n",
    "    # Track extracted organisms\n",
    "    extracted_organisms = []\n",
    "   \n",
    "    # Process each row of sub-images\n",
    "    for i, row in enumerate(sub_images):\n",
    "        for j, sub_image in enumerate(row):\n",
    "            # Remove white rows and columns\n",
    "            squeezed_image = squeeze_white_pixels(sub_image)\n",
    "           \n",
    "            # Get dimensions\n",
    "            h, w = squeezed_image.shape[:2]\n",
    "           \n",
    "            # Check if image meets minimum size requirements\n",
    "            if h > min_size and w > min_size:\n",
    "                # Generate an identifier for this organism\n",
    "                identifier = f\"{base_name}_organism_{i}_{j}_{w}_{h}\"\n",
    "                \n",
    "                # Ensure the image is in RGB format (in case it's RGBA)\n",
    "                if squeezed_image.shape[2] == 4:\n",
    "                    # Convert RGBA to RGB\n",
    "                    rgb_image = Image.fromarray(squeezed_image).convert('RGB')\n",
    "                    squeezed_image = np.array(rgb_image)\n",
    "                \n",
    "                # Add to extracted organisms\n",
    "                extracted_organisms.append((identifier, squeezed_image))\n",
    "                print(f\"Extracted: organism at position ({i},{j}) with size {w}x{h}\")\n",
    "   \n",
    "    print(f\"\\nTotal organisms extracted: {len(extracted_organisms)}\")\n",
    "    return extracted_organisms\n",
    "\n",
    "def find_organisms_in_raw_image(raw_image_path, organism_images):\n",
    "    \"\"\"\n",
    "    Find extracted organisms in the raw image and return their bounding box coordinates.\n",
    "    \n",
    "    Args:\n",
    "        raw_image_path: Path to the raw plankton image\n",
    "        organism_images: List of (filename, image_array) tuples\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples (organism_filename, x, y, width, height) where x,y is the top-left corner\n",
    "    \"\"\"\n",
    "    # Load the raw image\n",
    "    raw_img = cv2.imread(raw_image_path)\n",
    "    raw_img_rgb = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if raw_img is None:\n",
    "        print(f\"Error: Could not read raw image at {raw_image_path}\")\n",
    "        return []\n",
    "    \n",
    "    if not organism_images:\n",
    "        print(\"No organism images provided\")\n",
    "        return []\n",
    "    \n",
    "    # Results list to store: (organism_filename, x, y, width, height)\n",
    "    detections = []\n",
    "    \n",
    "    # For each organism image\n",
    "    for filename, org_img_rgb in organism_images:\n",
    "        # Convert from PIL RGB to OpenCV BGR if needed\n",
    "        if isinstance(org_img_rgb, np.ndarray) and org_img_rgb.shape[2] == 3:\n",
    "            org_img_cv = cv2.cvtColor(org_img_rgb, cv2.COLOR_RGB2BGR)\n",
    "        else:\n",
    "            print(f\"Warning: Unexpected image format for {filename}\")\n",
    "            continue\n",
    "        \n",
    "        # Use template matching to find the organism in the raw image\n",
    "        result = cv2.matchTemplate(raw_img, org_img_cv, cv2.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        \n",
    "        # If good match found (adjust threshold as needed)\n",
    "        if max_val > 0.7:  # Adjust this threshold based on your images\n",
    "            # Get organism dimensions\n",
    "            h, w = org_img_rgb.shape[:2]\n",
    "            \n",
    "            # Store detection data: (filename, x, y, width, height)\n",
    "            detections.append((filename, max_loc[0], max_loc[1], w, h))\n",
    "            print(f\"Found {filename} at position {max_loc} with confidence {max_val:.2f}\")\n",
    "        else:\n",
    "            print(f\"Could not find a good match for {filename}. Best match: {max_val:.2f}\")\n",
    "            \n",
    "            # Try alternative matching with a lower threshold if needed\n",
    "            if max_val > 0.5:  # Lower threshold for backup detection\n",
    "                h, w = org_img_rgb.shape[:2]\n",
    "                detections.append((filename, max_loc[0], max_loc[1], w, h))\n",
    "                print(f\"Using best available match for {filename}\")\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def visualize_detections(raw_image_path, detections, output_path):\n",
    "    \"\"\"\n",
    "    Create a visualization of the raw image with bounding boxes around detected organisms.\n",
    "    \n",
    "    Args:\n",
    "        raw_image_path: Path to the raw plankton image\n",
    "        detections: List of tuples (organism_filename, x, y, width, height)\n",
    "        output_path: Path to save the visualization\n",
    "    \"\"\"\n",
    "    # Load the raw image for visualization\n",
    "    raw_img = cv2.imread(raw_image_path)\n",
    "    if raw_img is None:\n",
    "        print(f\"Error: Could not read raw image at {raw_image_path}\")\n",
    "        return\n",
    "    \n",
    "    raw_img_rgb = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(1, figsize=(16, 10))\n",
    "    \n",
    "    # Display the raw image\n",
    "    ax.imshow(raw_img_rgb)\n",
    "    \n",
    "    # Add bounding boxes for each detection\n",
    "    for i, (filename, x, y, w, h) in enumerate(detections):\n",
    "        # Create a rectangle patch\n",
    "        rect = Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        \n",
    "        # Add the rectangle to the plot\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        ax.text(x, y-5, f\"{i+1}: {filename.split('_')[2]}\", color='red', fontsize=8, \n",
    "                bbox=dict(facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # Remove axis ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Set title\n",
    "    ax.set_title(f\"Detected Organisms: {len(detections)}\")\n",
    "    \n",
    "    # Save the visualization\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Visualization saved to {output_path}\")\n",
    "    \n",
    "    # Also create a version with CV2 for direct image manipulation\n",
    "    for filename, x, y, w, h in detections:\n",
    "        cv2.rectangle(raw_img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        # Add a simple label with the organism index\n",
    "        cv2.putText(raw_img, f\"{filename.split('_')[2]}\", (x, y-5), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    \n",
    "    cv2.imwrite(output_path.replace('.png', '_cv2.jpg'), raw_img)\n",
    "    \n",
    "def export_to_yolo_format(raw_image_path, detections, output_folder, class_mapping=None):\n",
    "    \"\"\"\n",
    "    Export detections to YOLO format.\n",
    "    \n",
    "    YOLO format: <class> <x_center> <y_center> <width> <height>\n",
    "    Where all values are normalized between 0 and 1.\n",
    "    \n",
    "    Args:\n",
    "        raw_image_path: Path to the raw plankton image\n",
    "        detections: List of tuples (organism_filename, x, y, width, height)\n",
    "        output_folder: Folder to save YOLO annotations\n",
    "        class_mapping: Dictionary mapping organism filenames to class indices\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get raw image dimensions\n",
    "    raw_img = cv2.imread(raw_image_path)\n",
    "    if raw_img is None:\n",
    "        print(f\"Error: Could not read raw image at {raw_image_path}\")\n",
    "        return\n",
    "    \n",
    "    img_height, img_width = raw_img.shape[:2]\n",
    "    \n",
    "    # If no class mapping provided, create a simple one\n",
    "    if class_mapping is None:\n",
    "        # Extract organism types from filenames\n",
    "        organism_types = set()\n",
    "        for filename, _, _, _, _ in detections:\n",
    "            # Try to get organism position from filename (e.g., \"base_organism_i_j_w_h.jpg\")\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) > 2:\n",
    "                organism_type = parts[2]  # Use the row index as the class\n",
    "            else:\n",
    "                organism_type = \"organism\"  # Default if can't extract from filename\n",
    "            organism_types.add(organism_type)\n",
    "        \n",
    "        # Create mapping from organism types to class indices\n",
    "        class_mapping = {organism_type: i for i, organism_type in enumerate(sorted(organism_types))}\n",
    "        \n",
    "        # Create class names file\n",
    "        with open(os.path.join(output_folder, 'classes.txt'), 'w') as f:\n",
    "            for organism_type in sorted(organism_types):\n",
    "                f.write(f\"plankton_class_{organism_type}\\n\")\n",
    "    \n",
    "    # Create YOLO annotation file\n",
    "    base_name = os.path.splitext(os.path.basename(raw_image_path))[0]\n",
    "    annotation_path = os.path.join(output_folder, f\"{base_name}.txt\")\n",
    "    \n",
    "    with open(annotation_path, 'w') as f:\n",
    "        for filename, x, y, width, height in detections:\n",
    "            # Determine class from filename\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) > 2:\n",
    "                organism_type = parts[2]  # Use the row index as the class\n",
    "            else:\n",
    "                organism_type = \"organism\"\n",
    "            \n",
    "            # Get class index\n",
    "            if organism_type in class_mapping:\n",
    "                class_idx = class_mapping[organism_type]\n",
    "            else:\n",
    "                print(f\"Warning: No class mapping for {organism_type}, using 0\")\n",
    "                class_idx = 0\n",
    "            \n",
    "            # Convert to YOLO format (normalized)\n",
    "            x_center = (x + width / 2) / img_width\n",
    "            y_center = (y + height / 2) / img_height\n",
    "            w_normalized = width / img_width\n",
    "            h_normalized = height / img_height\n",
    "            \n",
    "            # Write to file\n",
    "            f.write(f\"{class_idx} {x_center:.6f} {y_center:.6f} {w_normalized:.6f} {h_normalized:.6f}\\n\")\n",
    "    \n",
    "    print(f\"YOLO annotations saved to {annotation_path}\")\n",
    "    print(f\"Class mapping: {class_mapping}\")\n",
    "    \n",
    "    # Create YOLO dataset configuration\n",
    "    dataset_config = f\"\"\"\n",
    "# YOLO Dataset Configuration\n",
    "train: {output_folder}/train\n",
    "val: {output_folder}/val\n",
    "test: {output_folder}/test\n",
    "\n",
    "# number of classes\n",
    "nc: {len(class_mapping)}\n",
    "\n",
    "# class names\n",
    "names: {[f\"plankton_class_{idx}\" for idx in sorted(class_mapping.keys())]}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(os.path.join(output_folder, 'dataset.yaml'), 'w') as f:\n",
    "        f.write(dataset_config)\n",
    "    \n",
    "    print(f\"Dataset configuration saved to {os.path.join(output_folder, 'dataset.yaml')}\")\n",
    "    \n",
    "    # Copy the raw image to the YOLO images folder\n",
    "    images_folder = os.path.join(output_folder, 'images')\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "    \n",
    "    image_output_path = os.path.join(images_folder, os.path.basename(raw_image_path))\n",
    "    cv2.imwrite(image_output_path, raw_img)\n",
    "    \n",
    "    # Create directory structure for YOLO dataset\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(output_folder, split, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_folder, split, 'labels'), exist_ok=True)\n",
    "    \n",
    "    # Copy the raw image to the train folder as an example\n",
    "    train_image_path = os.path.join(output_folder, 'train', 'images', os.path.basename(raw_image_path))\n",
    "    cv2.imwrite(train_image_path, raw_img)\n",
    "    \n",
    "    # Copy the annotation to the train folder\n",
    "    train_annotation_path = os.path.join(output_folder, 'train', 'labels', f\"{base_name}.txt\")\n",
    "    with open(annotation_path, 'r') as f_src, open(train_annotation_path, 'w') as f_dst:\n",
    "        f_dst.write(f_src.read())\n",
    "    \n",
    "    print(f\"YOLO dataset structure created in {output_folder}\")\n",
    "\n",
    "def process_plankton_images(raw_image_path, sorted_image_path, min_size=50, output_folder=\"output\"):\n",
    "    \"\"\"\n",
    "    Complete workflow: extract organisms from sorted image, locate them in raw image,\n",
    "    create visualizations and export to YOLO format.\n",
    "    \n",
    "    Args:\n",
    "        raw_image_path: Path to the raw plankton image\n",
    "        sorted_image_path: Path to the sorted image with organisms on white background\n",
    "        min_size: Minimum size for an organism to be included\n",
    "        output_folder: Folder to save all outputs\n",
    "    \"\"\"\n",
    "    # Create base output folder\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # 1. Extract organisms from sorted image (in memory)\n",
    "    print(\"1. Extracting organisms from sorted image...\")\n",
    "    extracted_organisms = extract_organisms(sorted_image_path, min_size)\n",
    "    \n",
    "    # 2. Find organisms in the raw image\n",
    "    print(\"\\n2. Finding organisms in raw image...\")\n",
    "    detections = find_organisms_in_raw_image(raw_image_path, extracted_organisms)\n",
    "    \n",
    "    if detections:\n",
    "        # 3. Visualize detections\n",
    "        print(f\"\\n3. Creating visualization for {len(detections)} detected organisms...\")\n",
    "        visualize_detections(raw_image_path, detections, \n",
    "                           os.path.join(output_folder, \"detection_visualization.png\"))\n",
    "        \n",
    "        # 4. Export to YOLO format\n",
    "        print(\"\\n4. Exporting to YOLO format...\")\n",
    "        yolo_folder = os.path.join(output_folder, \"yolo_dataset\")\n",
    "        export_to_yolo_format(raw_image_path, detections, yolo_folder)\n",
    "        \n",
    "        print(f\"\\nComplete! All results saved to {output_folder}\")\n",
    "    else:\n",
    "        print(\"\\nNo organisms were detected in the raw image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Main function to run the workflow.\"\"\"\n",
    "# Replace these paths with your actual paths\n",
    "raw_image_path = r\"C:\\Users\\acer\\Desktop\\Work_IGB\\Georgia Zooplankton\\igb-georgia\\data\\Zooplankton scanner raw and sorted images\\raw_and_sorted\\M3A_2011-08-27__45um_above200um_x1_2400dpi_1-of-3.jpg\"  # Path to your raw plankton image\n",
    "sorted_image_path = r\"C:\\Users\\acer\\Desktop\\Work_IGB\\Georgia Zooplankton\\igb-georgia\\data\\Zooplankton scanner raw and sorted images\\raw_and_sorted\\M3A_2011-08-27__45um_above200um_x1_2400dpi_1-of-3_sorted.jpg\"     # Path to sorted image with organisms\n",
    "output_folder = r\"C:\\Users\\acer\\Desktop\\Work_IGB\\Georgia Zooplankton\\igb-georgia\\output\"                           # Output folder for results\n",
    "min_size = 200                                      # Minimum size for an organism\n",
    "\n",
    "# Process the images\n",
    "process_plankton_images(raw_image_path, sorted_image_path, min_size, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IGBv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
